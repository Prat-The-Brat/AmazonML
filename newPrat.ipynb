{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing part 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              filename  entity_name extracted_value\n",
      "0      61Mxgdk7NES.jpg  item_weight        100 gram\n",
      "1      712Q9pScGsL.jpg  item_weight                \n",
      "2      717en-V4EDL.jpg  item_weight     14 kilogram\n",
      "3      613MHCt4UvL.jpg  item_weight                \n",
      "4      61dphjNagYL.jpg  item_weight                \n",
      "...                ...          ...             ...\n",
      "22173  718YXdgUJqL.jpg  item_weight   900 milligram\n",
      "22174  61U31F+JKJL.jpg  item_weight                \n",
      "22175  61Ueu26MdmL.jpg  item_weight    20 milligram\n",
      "22176  51Onc432L8L.jpg  item_weight                \n",
      "22177  61tjv5nAYgL.jpg  item_weight        170 gram\n",
      "\n",
      "[22178 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the preprocessed CSV file\n",
    "data = pd.read_csv('/Users/prathambhonge/AmazonML/final_updated.csv')\n",
    "\n",
    "# Convert text to lowercase and remove special characters, handling missing or non-string values\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):  # Check if the value is a string\n",
    "        return re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    return ''  # Return an empty string for non-string values\n",
    "\n",
    "data['clean_text'] = data['text'].apply(clean_text)\n",
    "\n",
    "# Example: For 'item_weight', map possible units and normalize values\n",
    "unit_patterns = {\n",
    "    'gram': r'\\b(\\d+\\.?\\d*)\\s*(g|gram|grams)\\b',\n",
    "    'kilogram': r'\\b(\\d+\\.?\\d*)\\s*(kg|kilogram|kilograms)\\b',\n",
    "    'milligram': r'\\b(\\d+\\.?\\d*)\\s*(mg|milligram|milligrams)\\b',\n",
    "    'pound': r'\\b(\\d+\\.?\\d*)\\s*(lb|pound|pounds)\\b',\n",
    "    'ounce': r'\\b(\\d+\\.?\\d*)\\s*(oz|ounce|ounces)\\b',\n",
    "    'ton': r'\\b(\\d+\\.?\\d*)\\s*(ton|tons)\\b'\n",
    "}\n",
    "\n",
    "def extract_value(text, entity_name):\n",
    "    if entity_name == 'item_weight':\n",
    "        for unit, pattern in unit_patterns.items():\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                return f\"{match.group(1)} {unit}\"\n",
    "    return ''\n",
    "\n",
    "# Apply the extraction function\n",
    "data['extracted_value'] = data.apply(lambda row: extract_value(row['clean_text'], row['entity_name']), axis=1)\n",
    "\n",
    "# Display the dataframe with extracted values\n",
    "print(data[['filename', 'entity_name', 'extracted_value']])\n",
    "\n",
    "# Save the processed data to a new CSV file\n",
    "data.to_csv('processed_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split completed. Train data: 17742 samples, Test data: 4436 samples.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the processed CSV file\n",
    "data = pd.read_csv('processed_data.csv')\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the training data to a CSV file\n",
    "train_data.to_csv('train_data.csv', index=False)\n",
    "\n",
    "# Save the testing data to a CSV file\n",
    "test_data.to_csv('test_data.csv', index=False)\n",
    "\n",
    "# Output a confirmation message\n",
    "print(f\"Data split completed. Train data: {len(train_data)} samples, Test data: {len(test_data)} samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y7/z5jsjvm114q5ghxnsprd37n00000gn/T/ipykernel_27174/1435345197.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data['text'].fillna('', inplace=True)\n",
      "/var/folders/y7/z5jsjvm114q5ghxnsprd37n00000gn/T/ipykernel_27174/1435345197.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data['entity_name'].fillna('', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on validation set: 6.02562795792511e+22\n",
      "Model training completed and saved to 'entity_value_prediction_model.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import re\n",
    "\n",
    "# Load the training data\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "\n",
    "# Handle missing values in 'text' and 'entity_name'\n",
    "train_data['text'].fillna('', inplace=True)\n",
    "train_data['entity_name'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the text and entity_name columns for better feature representation\n",
    "train_data['input_text'] = train_data['text'] + ' ' + train_data['entity_name']\n",
    "\n",
    "# Function to extract numeric values from the 'entity_value' column\n",
    "def extract_numeric_value(value):\n",
    "    # Regular expression to extract the first number from the string\n",
    "    match = re.search(r'(\\d+\\.?\\d*)', str(value))\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return None\n",
    "\n",
    "# Apply the function to the 'entity_value' column\n",
    "train_data['numeric_value'] = train_data['entity_value'].apply(extract_numeric_value)\n",
    "\n",
    "# Drop rows with missing numeric values\n",
    "train_data.dropna(subset=['numeric_value'], inplace=True)\n",
    "\n",
    "# Separate the input features (X) and target variable (y)\n",
    "X = train_data['input_text']\n",
    "y = train_data['numeric_value']\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the pipeline: TF-IDF Vectorizer + Random Forest Regressor\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(max_features=5000),  # Convert text into numeric features\n",
    "    RandomForestRegressor(n_estimators=100, random_state=42)  # Random Forest model\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = pipeline.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "print(f\"Mean Squared Error on validation set: {mse}\")\n",
    "\n",
    "# Save the trained model for future predictions\n",
    "import joblib\n",
    "joblib.dump(pipeline, 'entity_value_prediction_model_new.pkl')\n",
    "\n",
    "print(\"Model training completed and saved to 'entity_value_prediction_model.pkl'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y7/z5jsjvm114q5ghxnsprd37n00000gn/T/ipykernel_27174/2890022316.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data['text'].fillna('', inplace=True)\n",
      "/var/folders/y7/z5jsjvm114q5ghxnsprd37n00000gn/T/ipykernel_27174/2890022316.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data['entity_name'].fillna('', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8212125474750317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.17      0.28      1464\n",
      "           1       0.71      0.98      0.82      2972\n",
      "\n",
      "    accuracy                           0.71      4436\n",
      "   macro avg       0.76      0.58      0.55      4436\n",
      "weighted avg       0.74      0.71      0.64      4436\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Load the trained model\n",
    "pipeline = joblib.load('entity_value_prediction_model_new.pkl')\n",
    "\n",
    "# Load the validation data\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Handle missing values in 'text' and 'entity_name'\n",
    "test_data['text'].fillna('', inplace=True)\n",
    "test_data['entity_name'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the text and entity_name columns for better feature representation\n",
    "test_data['input_text'] = test_data['text'] + ' ' + test_data['entity_name']\n",
    "\n",
    "# Make predictions on the test set\n",
    "X_test = test_data['input_text']\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Extract numeric values from the entity_value column in the test data\n",
    "def extract_numeric_value(value):\n",
    "    match = re.search(r'(\\d+\\.?\\d*)', str(value))\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return None\n",
    "\n",
    "test_data['numeric_value'] = test_data['entity_value'].apply(extract_numeric_value)\n",
    "\n",
    "# Drop rows with missing numeric values in the test set\n",
    "test_data.dropna(subset=['numeric_value'], inplace=True)\n",
    "\n",
    "# True values for validation\n",
    "y_true = test_data['numeric_value']\n",
    "\n",
    "# Convert numeric values to binary classes (0 or 1) based on a threshold\n",
    "threshold = 10  # Define a threshold for binarization\n",
    "y_true_binary = (y_true > threshold).astype(int)\n",
    "y_pred_binary = (y_pred > threshold).astype(int)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_true_binary, y_pred_binary)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Print classification report for detailed metrics\n",
    "print(classification_report(y_true_binary, y_pred_binary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y7/z5jsjvm114q5ghxnsprd37n00000gn/T/ipykernel_27174/2636769917.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data['text'].fillna('', inplace=True)\n",
      "/var/folders/y7/z5jsjvm114q5ghxnsprd37n00000gn/T/ipykernel_27174/2636769917.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data['entity_name'].fillna('', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'test_predictions.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('entity_value_prediction_model_new.pkl')\n",
    "\n",
    "# Define the allowed units\n",
    "allowed_units = {\n",
    "    \"width\": {\"centimetre\", \"foot\", \"millimetre\", \"metre\", \"inch\", \"yard\"},\n",
    "    \"depth\": {\"centimetre\", \"foot\", \"millimetre\", \"metre\", \"inch\", \"yard\"},\n",
    "    \"height\": {\"centimetre\", \"foot\", \"millimetre\", \"metre\", \"inch\", \"yard\"},\n",
    "    \"item_weight\": {\"milligram\", \"kilogram\", \"microgram\", \"gram\", \"ounce\", \"ton\", \"pound\"},\n",
    "    \"maximum_weight_recommendation\": {\"milligram\", \"kilogram\", \"microgram\", \"gram\", \"ounce\", \"ton\", \"pound\"},\n",
    "    \"voltage\": {\"millivolt\", \"kilovolt\", \"volt\"},\n",
    "    \"wattage\": {\"kilowatt\", \"watt\"},\n",
    "    \"item_volume\": {\"cubic foot\", \"microlitre\", \"cup\", \"fluid ounce\", \"centilitre\", \"imperial gallon\", \"pint\", \"decilitre\", \"litre\", \"millilitre\", \"quart\", \"cubic inch\", \"gallon\"}\n",
    "}\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Handle missing values in 'text' and 'entity_name'\n",
    "test_data['text'].fillna('', inplace=True)\n",
    "test_data['entity_name'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the text and entity_name columns for feature representation\n",
    "test_data['input_text'] = test_data['text'] + ' ' + test_data['entity_name']\n",
    "\n",
    "# Predict the numeric values\n",
    "predictions = model.predict(test_data['input_text'])\n",
    "\n",
    "# Map the predictions to the allowed units\n",
    "# For simplicity, this example will use a default unit 'gram'. You should adapt this as needed.\n",
    "def format_prediction(value, unit=\"gram\"):\n",
    "    if unit in allowed_units.get(test_data['entity_name'][0], []):\n",
    "        return f\"{value:.2f} {unit}\"\n",
    "    return \"\"\n",
    "\n",
    "# Apply the formatting function\n",
    "test_data['prediction'] = [format_prediction(pred) for pred in predictions]\n",
    "\n",
    "# Prepare the output DataFrame\n",
    "output = pd.DataFrame({\n",
    "    'index': test_data.index,  # Use the DataFrame index directly\n",
    "    'prediction': test_data['prediction']\n",
    "})\n",
    "\n",
    "# Save the output to a CSV file\n",
    "output.to_csv('test_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'test_predictions.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
